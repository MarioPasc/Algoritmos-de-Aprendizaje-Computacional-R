---
title: "Algoritmos de Aprendizaje Computacional"
author: "Mario Pascual González"
format:
  html:
    theme:
      light: flatly
      dark: darkly
    highlight-style: monokai  # Monokai también funciona bien en temas oscuros
    toc: true
    toc-depth: 3
    toc-title: "Contenidos"
    toc-float:
      collapsed: false
      smooth-scroll: true
    toc_scroll: true
    number-sections: true
    code-fold: true
    code-tools: 
      source: true
      toggle: true
      caption: "Expand Code"
      
    html-math-method: katex
    bibliography: references.bib
    lang: es
    other-links:
      - text: LinkedIn
        icon: linkedin
        href: 'https://www.linkedin.com/in/mario-pascual-gonzalez/'
      - text: Correo Electrónico
        icon: envelope
        href: "mailto:mario.pg02@gmail.com?subject=Contacto desde el informe de Modelado Predictivo"
      - text: Perfil de Github
        icon: github
        href: 'https://github.com/MarioPasc'
    code-links:
      - text: Repositorio del Informe
        icon: file-code
        href: 'https://github.com/MarioPasc/Modelado-Predictivo-Cancer-de-Mama-R'
---

```{r setup}
#| output: false
#| echo: false
#| warning: false

library(glmnet)
library(caret)
library(readxl)
library(readr)
library(ggplot2)
library(dplyr)
library(broom)
library(DT)
library(tidyverse)
library(reshape2)
library(MASS)
library(pROC)
library(e1071)
library(nnet)
library(rpart)

data <- read.csv(file = "./data/datos_limpios.csv", sep = ",", dec=".")
data["X"] <- NULL
nuevo_orden <- c("Edad", "REst", "RPro", "Her2", "Estadio", "NodAfec", "Grado", "Fenotipo", "Estudio", "PCR")
data <- data[, nuevo_orden]
```

```{r global.options, include = TRUE}
knitr::opts_chunk$set(
    cache       = TRUE,     # if TRUE knitr will cache the results to reuse in future knits
    fig.width   = 7,       # the width for plots created by code chunk
    fig.height  = 4,       # the height for plots created by code chunk
    fig.align   = 'center', # how to align graphics in the final doc. 'left', 'right', 'center'
    fig.path    = 'figs/',  # file path to the directory where knitr shall store the graphics files
    results     = 'asis',   # knitr will pass through results without reformatting them
    echo        = TRUE,     # in FALSE knitr will not display code in the code chunk above it's results
    message     = TRUE,     # if FALSE knitr will not display any messages generated by code
    strip.white = TRUE,     # if FALSE knitr will not remove white spaces at the beg or end of code chunk
    warning     = FALSE)    # if FALSE knitr will not display any warning messages in the final document
```

# Exploración de los Datos

Los datos que con los que se tratará en este documento son datos reales clínicos, provistos por el Dr. Jose Manuel Jerez Aragonés. El fichero fue previamente pre-procesado en el proyecto anterior a este, [Modelado Predictivo para el Cáncer de Mama en R](https://github.com/MarioPasc/Modelado-Predictivo-Cancer-de-Mama-R/tree/main), y, las técnicas usadas incluyen pipelines de imputación de valores faltantes (cuantitavios con la mediana y cualitativos con la moda), manipulación de valores categóricos erróneos, eliminación de *outliers*, y otras técnicas. Es por eso que este apartado será dedicado a explorar la distribución de las variables de estos datos con la finalidad de ayudar a identificar sesgos dentro de variables que luego puedan ser mitigados mediante técnicas de validación interna de modelos. 

```{r}
convert_to_factors <- function(data, variable_list) {
  if (!is.data.frame(data)) {
    stop("El primer argumento debe ser un data.frame.")
  }
  if (!is.vector(variable_list) || !all(variable_list %in% names(data))) {
    stop("El segundo argumento debe ser un vector con nombres de columnas válidas del data.frame.")
  }
  
  for (variable_name in variable_list) {
    data[[variable_name]] <- as.factor(data[[variable_name]])
  }
  
  return(data)
}

data <- convert_to_factors(data, c("REst", "RPro", "Her2", "Estadio", "NodAfec", "Grado", "Fenotipo", "Estudio", "PCR"))

knitr::kable(head(data, 10))
```

```{r}
blue = '#377eb8'
red = '#e41a1c'
plot_variable_distribution <- function(data, variable_name, target_name) {
  # Comprobar si las variables existen en el data.frame
  if (!(variable_name %in% names(data) && target_name %in% names(data))) {
    stop("Una o ambas variables especificadas no existen en el data.frame proporcionado.")
  }
  
  # Extraer la variable y la variable target del data.frame
  variable <- data[[variable_name]]
  target <- data[[target_name]]
  
  # Asegurar que la variable target es factor
  data[[target_name]] <- as.factor(data[[target_name]])
  
  # Determinar si la variable principal es numérica o factor
  if (is.numeric(variable)) {
    # Crear un histograma para variables numéricas
    p <- ggplot(data, aes_string(x = variable_name, fill = target_name)) +
      geom_histogram(position = "identity", alpha = 0.5, bins = 30) +
      scale_fill_manual(values = c("0" = blue, "1" = red)) +
      ggtitle(paste("Distribución de", variable_name, "por", target_name)) +
      xlab(variable_name) +
      ylab("Frecuencia")
  } else if (is.factor(variable)) {
    # Crear un gráfico de barras para factores
    p <- ggplot(data, aes_string(x = variable_name, fill = target_name)) +
      geom_bar(position = "stack") +
      scale_fill_manual(values = c("0" = blue, "1" = red)) +
      ggtitle(paste("Distribución de", variable_name, "por", target_name)) +
      xlab(variable_name) +
      ylab("Frecuencia") +
      theme(legend.position = "right")
  } else {
    stop("El tipo de la variable debe ser numérico o factor.")
  }
  
  # Imprimir el gráfico
  print(p)
}

```

::: {.panel-tabset}

## Edad

```{r}
plot_variable_distribution(data, "Edad", "PCR")
```

## REst

```{r}
plot_variable_distribution(data, "REst", "PCR")
```

## RPro

```{r}
plot_variable_distribution(data, "RPro", "PCR")
```

## Her2

```{r}
plot_variable_distribution(data, "Her2", "PCR")
```

## Estadio

```{r}
plot_variable_distribution(data, "Estadio", "PCR")
```

## NodAfec

```{r}
plot_variable_distribution(data, "NodAfec", "PCR")
```

## Grado

```{r}
plot_variable_distribution(data, "Grado", "PCR")
```

## Fenotipo

```{r}
plot_variable_distribution(data, "Fenotipo", "PCR")
```

## Estudio

```{r}
plot_variable_distribution(data, "Estudio", "PCR")
```

## PCR

```{r}
plot_variable_distribution(data, "PCR", "PCR")
```

:::

Como se puede observar en las gráficas anteriores, el conjunto de datos se encuentra **desbalanceado** con respecto a la variable objetivo, PCR, a lo largo de todas las demás variables del conjunto de datos. Esto se evidencia al visualizar la propia distribución de la variable PCR, la cual muestra la falta de entradas positivas, algo normal en los estudios clínicos en los que una connotación negativa está asociada a la muestra positiva -en este caso, la metástasis del cáncer. 

Observando el resto de gráficas, se pueden notar otros fenómenos que podrían introducir un sesgo en nuestros datos. La variable `Her2`, por ejemplo, se encuentra totalmente desbalanceada, teniendo una cantidad ínfima de muestras para Her2-Positivo. Para poder tener en cuenta cómo estos datos se relacionan con la variable objetivo, y así poder determinar si la excasa cantidad de estos afecta de una manera muy negativa la predicción de nuestro modelo, se realizará un *análisis de asociación*. 

# Selección de características

## Análisis de Asociación

```{r, warning=FALSE, message=FALSE}
source("./aux_scripts/calculaPValor.R")
plot <- plot_p_valores(data)
print(plot)
```

Como se puede observar en la salida del modelo de regresión logística, las variables que muestran una asociación estadísticamente significativa con la variable objetivo PCR son **Estadio, Fenotipo, Grado, REst, y RPro**. Estas variables han sido seleccionadas mediante un proceso iterativo que utiliza el algoritmo `stepAIC`, el cual optimiza el modelo añadiendo o eliminando variables para minimizar el criterio de información de Akaike (AIC). Este enfoque no solo confirma la significancia estadística inicial observada en los análisis de p-valores, sino que también ajusta el modelo para incluir solo las variables más informativas.

```{r}
source("./aux_scripts/calculaPValor.R")

ajustado <- ajustarModeloLogistico(data, "PCR", "Estadio + Fenotipo + Grado + REst + RPro")
asociacion <- c("Estadio", "Fenotipo", "Grado", "REst", "RPro")
variables_seleccionadas <- ajustado$variables_seleccionadas
variables_asociacion <- "Estadio+Fenotipo+Grado+REst+RPro"
```

El modelo final selecciona múltiples categorías dentro de las variables Estadio, Fenotipo, Grado, REst, y RPro que son determinantes para explicar la variable PCR. Estas categorías incluyen, por ejemplo, diferentes tipos de Estadio y Fenotipo, que muestran cómo varía la probabilidad de PCR en función de estas características. Este conjunto de variables y categorías será denominado de ahora en adelante como Asociacion, en referencia al método efectivo de selección de variables utilizado.

# Modelos Predictivos Avanzados

El principal objetivo de este proyecto es el de poder predecir si un paciente será PCR-Positivo (Metástasis) mediante el uso de Algoritmos de Aprendizaje Computacional para el procesamiento de los datos de cáncer de mama previamente curados. Para poder conseguir el modelo que más se ajuste a esta tarea, se debe realizar una selección de características sobre el conjunto de datos y un ajuste fino (*fine-tuning*) de los parámetros del modelo de predicción. Todo esto debe ser llevado a cabo utilizando métodos de validación interna que eliminen cualquier tipo de sesgo inherente dentro de los datos en la variable objetivo, asegurando unos resultados estables para la evaluación del rendimiento del modelo para datos a futuro.  

## Rendimiento Aparente

Para poder realizar una estimación de cómo de bien los modelos conseguirán predecir sobre el conjunto de datos se va a realizar una estimación del rendimiento aparente. Esto consistirá en entrenar con todo el conjunto de datos, y evaluar con estos mismos datos. De esta forma, podremos evaluar la capacidad predictiva del modelo antes de intentar encontrar una manera estable de obtener los métricas de rendimiento -es decir, aplicar una validación interna.

### Máquinas de Vectores de Soporte (SVM)

```{r}
source("./aux_scripts/procedimientosMachineLearning.R")

svm_model <- function(formula, data) {
  x <- model.matrix(formula, data)
  y <- data[[all.vars(formula)[1]]]
  y <- factor(y, levels = c(0, 1))
  svm(x = x, y = y, kernel = "poly", cost = 20, gamma = .5, probability = TRUE)
}
#  svm(x = x, y = y, kernel = "sigmoid", cost = 18, gamma = .5, probability = TRUE)
#  svm(x = x, y = y, kernel = "radial", cost = 5, gamma = .5, probability = TRUE)
#  svm(x = x, y = y, kernel = "poly", cost = 20, gamma = .5, probability = TRUE)


resultadosAparentesSVM <- evaluate_aparent_performance_model(data = data, target_var = "PCR",
                                                             model_func = svm_model,
                                                             vars = variables_asociacion,
                                                             threshold = .35)
resultadosAparentesSVM$confusion_matrix
resultadosAparentesSVM$roc_curve$auc
print("Accuracy: ")
resultadosAparentesSVM$accuracy
print("Precision: ")
resultadosAparentesSVM$precision
print("Recall: ")
resultadosAparentesSVM$recall
print("F1-Score: ")
resultadosAparentesSVM$f1_score
```
### Redes de Neuronas Artificiales (ANN)

```{r}
source("./aux_scripts/procedimientosMachineLearning.R")

nn_model <- function(formula, data) {
  nnet(formula = formula, data = data, size = 30, 
       decay = 0.1, maxit = 100, trace = FALSE, 
       linout = FALSE, random_state = 42)
}


resultadosAparentesSVM <- evaluate_aparent_performance_model(data = data, target_var = "PCR",
                                                             model_func = nn_model,
                                                             vars = variables_asociacion,
                                                             threshold = .35)
resultadosAparentesSVM$confusion_matrix
resultadosAparentesSVM$roc_curve$auc
print("Accuracy: ")
resultadosAparentesSVM$accuracy
print("Precision: ")
resultadosAparentesSVM$precision
print("Recall: ")
resultadosAparentesSVM$recall
print("F1-Score: ")
resultadosAparentesSVM$f1_score
```

## Validación Interna

### División de los datos

Como se ha visto anteriormente, el conjunto de datos sufre de un desbalance en su variable objetivo, PCR. Si bien se evaluará la capacidad predictiva de cada modelo entrenando y evaluando con todos los datos, se necesitará alguna forma de cuantificar el rendimiento del modelo para datos a futuro. 

Debido a que los modelos con los que se va a trabajar a continuación son algoritmos complejos y con una etapa de entrenamiento y ajuste fino complejas, se nos introduce la necesidad de dividir el conjunto de datos en 3 conjuntos: *entrenamiento, validación* y *test*. La justificación de no realizar simplemente una división de *train* y *test* reside en que cuando solo se utiliza un conjunto de entrenamiento y uno de prueba, existe el riesgo de que el ajuste fino del modelo se haga específicamente para maximizar el rendimiento en el conjunto de prueba. Esto puede llevar a un modelo que esté sobreajustado a las características específicas de este conjunto de datos, lo que disminuye su capacidad para generalizar a nuevos datos. El conjunto de validación permitirá entonces ajustar los hiperparámetros y hacer selecciones de modelo sin "contaminar" el conjunto de prueba, que se reserva para una evaluación final más objetiva.

Adicionalmente, mantener el conjunto de prueba completamente independiente de cualquier decisión tomada durante el proceso de modelado asegura que el rendimiento evaluado en este conjunto es una representación honesta y no sesgada de cómo el modelo se comportará con datos nuevos y no vistos.

Esto se realizará guardando un conjunto de test totalmente separado del conjunto de entrenamiento. Este conjunto de test será "olvidado" hasta que se tenga que hacer la evaluación final de los modelos. El conjunto de entrenamiento se dividirá en validación, y, entrenamiento. Esta división se realizará dentro del modelo de validación interna que se decida usar. 

```{r}
source("./aux_scripts/procedimientosMachineLearning.R")
splitted_data <- train_test_split(data, 0.8, "PCR", "./data")

train_index <- splitted_data$train_index
plot <- splitted_data$plot
summary <- splitted_data$summary

train_data <- read.csv(file = "./data/train.csv", sep = ",", dec=".")
test_data <- read.csv(file = "./data/test.csv", sep = ",", dec=".")
```

::: {.panel-tabset}

## Gráfico de distribución de PCR en los diferentes conjuntos

```{r}
print(plot)
```

## Resumen de distribución de datos a través de conjuntos

```{r}
knitr::kable(summary)
```
:::

### Métodos de validación interna

Como se demuestra en [@gonzalez2024predictive], un estudio anterior realizado utilizando este mismo conjunto de datos para el diseño de un modelo pridctivo basado en la regresión logística, el método recomendado por la literatura, *k-fold cross validation* no funciona de una manera efectiva con estas muestras. Esto se debe a que el desbalance de la variable objetivo y la moderada cantidad de datos hace que el rendimiento del modelo se vea limitado al elegir un k demasiado bajo, ya que las métricas se vuelven poco representativas, y un k demasiado alto, ya que los folds se vuelven poco representativos al disminuir la varianza de los datos de cada uno, haciendo que el rendimiento se vuelva inestable. 

Es por esto que, a lo largo de este estudio, se utilizará un método de validación basado en *Repeated Hold-Out* -con la misma semilla para asegurar la reproducibilidad. Para poder obtener un rendimiento representativo sin repetir divisiones de datos aleatorias, se harán 30 iteraciones. 

## Máquinas de Vectores de Soportte (SVM)

Una Máquina de Vectores de Soporte (SVM) es un algoritmo de aprendizaje supervisado utilizado para la clasificación y regresión. Su objetivo principal es encontrar el **hiperplano óptimo** que mejor separa las clases en el espacio de características. Los **vectores de soporte** son los puntos de datos más cercanos al hiperplano de separación y son cruciales para determinar su posición y orientación. Estos vectores de soporte son los puntos que definen el *"margen"*, que es la distancia entre el hiperplano y los puntos de datos más cercanos. Durante el entrenamiento, **el SVM busca el hiperplano que maximiza esta margen**. Para seleccionar los vectores de soporte, el SVM utiliza un proceso de optimización que busca minimizar una función de pérdida que penaliza la clasificación incorrecta de los puntos de datos. 

La **función kernel SVM** es una función que transforma los datos de entrada en un espacio de características de mayor dimensión, donde es más fácil encontrar un hiperplano de separación. Esto permite que el SVM maneje conjuntos de datos que no son linealmente separables en su espacio de características original. 

El **parámetro C** en SVM controla el balance entre la maximización de el margen y la clasificación incorrecta de los puntos de datos en el conjunto de entrenamiento. Un valor más bajo de C permite clasificar más puntos de datos correctamente en el conjunto de entrenamiento, pero puede conducir a un sobreajuste. Por otro lado, un valor más alto de C prioriza un margen más amplio, lo que puede resultar en una clasificación menos precisa en el conjunto de entrenamiento, pero puede generalizar mejor en datos no vistos.

El **parámetro gamma** en SVM controla el alcance de influencia de un solo ejemplo de entrenamiento. Un valor más alto de gamma significa que los puntos de datos más cercanos tienen un peso más significativo en la definición de la frontera de decisión, lo que puede conducir a un modelo más complejo y propenso al sobreajuste. Por el contrario, un valor más bajo de gamma significa que el alcance de influencia es más amplio y la frontera de decisión es más suave, sin embargo, esto podría llevar a un modelo que no generalice bien las características de los datos. 

```{r}
source("./aux_scripts/procedimientosMachineLearning.R")

svm_model <- function(formula, data) {
  x <- model.matrix(formula, data)
  y <- data[[all.vars(formula)[1]]]
  svm(x = x, y = y, kernel = "sigmoid", cost = .1, gamma = .1, probability = TRUE)
}

res <- repeated_holdout(train_data = train_data, val_ratio = .2, 
                        target_var = "PCR", n_iterations = 20, 
                        threshold = 0.35, vars = "Estadio+Fenotipo+Grado+REst+RPro", 
                        model_func=rf_model)
performance_data <- evaluate_holdout(results = res$results)
res$results
performance_data$avg_metrics
performance_data$plot
performance_data$metrics
```




```{r, warning=FALSE, message=FALSE}
source("./aux_scripts/procedimientosMachineLearning.R")

dt_model <- function(formula, data) {
  rpart(formula = formula, data = data, method = "class")
}

rf_model <- function(formula, data) {
  rpart(formula = formula, data = data, method = "class", control = rpart.control(minsplit = 2, cp = 0))
}

svm_model <- function(formula, data) {
  x <- model.matrix(formula, data)
  y <- data[[all.vars(formula)[1]]]
  svm(x = x, y = y, kernel = "sigmoid", cost = 10, gamma = 1, probability = TRUE)
}

nn_model <- function(formula, data) {
  nnet(formula = formula, data = data, size = 5, 
       decay = 0.1, maxit = 100, trace = FALSE, 
       linout = TRUE, random_state=42)
}



doubleCV <- double_cross_validation(data = train_data, val_ratio = .2, target_var = "PCR",
                                    outer_folds = 6, inner_folds = 5,
                                    threshold = .35, vars = "Estadio+Fenotipo+Grado+REst+RPro",
                                    model_func = nn_model)



performance_data <- evaluate_double_cross_validation(results=doubleCV$results)
doubleCV$results
performance_data$avg_metrics
performance_data$plot
performance_data$metrics
```



































